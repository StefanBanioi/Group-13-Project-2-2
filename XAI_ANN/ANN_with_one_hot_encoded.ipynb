{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras import optimizers\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                    396\n",
      "sex                      0\n",
      "weight                   0\n",
      "bmi                    956\n",
      "hereditary_diseases      0\n",
      "no_of_dependents         0\n",
      "smoker                   0\n",
      "city                     0\n",
      "bloodpressure            0\n",
      "diabetes                 0\n",
      "regular_ex               0\n",
      "job_title                0\n",
      "claim                    0\n",
      "dtype: int64\n",
      "age                    0\n",
      "sex                    0\n",
      "weight                 0\n",
      "bmi                    0\n",
      "hereditary_diseases    0\n",
      "no_of_dependents       0\n",
      "smoker                 0\n",
      "city                   0\n",
      "bloodpressure          0\n",
      "diabetes               0\n",
      "regular_ex             0\n",
      "job_title              0\n",
      "claim                  0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kobra\\AppData\\Local\\Temp\\ipykernel_304\\147386097.py:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data.replace(True, 1, inplace=True)\n",
      "C:\\Users\\kobra\\AppData\\Local\\Temp\\ipykernel_304\\147386097.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[col] = data.pop(col)\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "data = pd.read_csv('original_kaggle_healthinsurance.csv')\n",
    "\n",
    "data.head()\n",
    "\n",
    "#check if data contains missing values or nan\n",
    "print(data.isnull().sum())\n",
    "\n",
    "#drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "print(data.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "# Now apply get_dummies\n",
    "data = pd.get_dummies(data)\n",
    "\n",
    "data.replace(False, 0, inplace=True)\n",
    "data.replace(True, 1, inplace=True)\n",
    "\n",
    "#put claim column to the end\n",
    "def move_column_to_end(data, col):\n",
    "    data[col] = data.pop(col)\n",
    "\n",
    "# Usage\n",
    "move_column_to_end(data, 'claim')\n",
    "\n",
    "#transform pandas back into csv\n",
    "data.to_csv('one_hot_encoded.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>no_of_dependents</th>\n",
       "      <th>smoker</th>\n",
       "      <th>bloodpressure</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>regular_ex</th>\n",
       "      <th>claim</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>...</th>\n",
       "      <th>job_title_Journalist</th>\n",
       "      <th>job_title_Labourer</th>\n",
       "      <th>job_title_Lawyer</th>\n",
       "      <th>job_title_Manager</th>\n",
       "      <th>job_title_Photographer</th>\n",
       "      <th>job_title_Police</th>\n",
       "      <th>job_title_Politician</th>\n",
       "      <th>job_title_Singer</th>\n",
       "      <th>job_title_Student</th>\n",
       "      <th>job_title_Technician</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>64</td>\n",
       "      <td>24.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13112.6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.0</td>\n",
       "      <td>75</td>\n",
       "      <td>22.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9567.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>64</td>\n",
       "      <td>17.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32734.2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.0</td>\n",
       "      <td>53</td>\n",
       "      <td>36.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48517.6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>50</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1731.7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42.0</td>\n",
       "      <td>89</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6474.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.0</td>\n",
       "      <td>59</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1705.6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.0</td>\n",
       "      <td>52</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1534.3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40.0</td>\n",
       "      <td>69</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5910.9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>51.0</td>\n",
       "      <td>50</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44400.4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>59.0</td>\n",
       "      <td>68</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28287.9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.0</td>\n",
       "      <td>45</td>\n",
       "      <td>24.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1837.2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21.0</td>\n",
       "      <td>53</td>\n",
       "      <td>35.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2404.7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27.0</td>\n",
       "      <td>53</td>\n",
       "      <td>18.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4827.9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>56.0</td>\n",
       "      <td>67</td>\n",
       "      <td>40.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10602.4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>56.0</td>\n",
       "      <td>69</td>\n",
       "      <td>27.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11073.2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>63.0</td>\n",
       "      <td>67</td>\n",
       "      <td>41.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15555.2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>46</td>\n",
       "      <td>24.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2709.2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>52.0</td>\n",
       "      <td>76</td>\n",
       "      <td>38.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11396.9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27.0</td>\n",
       "      <td>53</td>\n",
       "      <td>18.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4827.9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  weight   bmi  no_of_dependents  smoker  bloodpressure  diabetes  \\\n",
       "0   60.0      64  24.3                 1       0             72         0   \n",
       "1   49.0      75  22.6                 1       0             78         1   \n",
       "2   32.0      64  17.8                 2       1             88         1   \n",
       "3   61.0      53  36.4                 1       1             72         1   \n",
       "4   19.0      50  20.6                 0       0             82         1   \n",
       "5   42.0      89  37.9                 0       0             78         0   \n",
       "6   18.0      59  23.8                 0       0             64         0   \n",
       "7   21.0      52  26.8                 0       0             74         1   \n",
       "9   40.0      69  29.6                 0       0             64         1   \n",
       "10  51.0      50  33.0                 0       1              0         1   \n",
       "11  59.0      68  36.5                 1       0             70         1   \n",
       "12  19.0      45  24.6                 1       0              0         0   \n",
       "13  21.0      53  35.7                 0       0             62         1   \n",
       "14  27.0      53  18.9                 3       0             90         1   \n",
       "15  56.0      67  40.3                 0       0              0         1   \n",
       "16  56.0      69  27.2                 0       0             68         1   \n",
       "17  63.0      67  41.3                 3       0             70         1   \n",
       "18  19.0      46  24.6                 1       0             70         1   \n",
       "19  52.0      76  38.4                 2       0             48         1   \n",
       "20  27.0      53  18.9                 3       0             90         1   \n",
       "\n",
       "    regular_ex    claim  sex_female  ...  job_title_Journalist  \\\n",
       "0            0  13112.6           0  ...                     0   \n",
       "1            1   9567.0           1  ...                     0   \n",
       "2            1  32734.2           1  ...                     0   \n",
       "3            0  48517.6           1  ...                     0   \n",
       "4            0   1731.7           1  ...                     0   \n",
       "5            0   6474.0           1  ...                     0   \n",
       "6            0   1705.6           0  ...                     0   \n",
       "7            0   1534.3           0  ...                     0   \n",
       "9            1   5910.9           1  ...                     0   \n",
       "10           0  44400.4           1  ...                     0   \n",
       "11           1  28287.9           1  ...                     0   \n",
       "12           1   1837.2           0  ...                     0   \n",
       "13           0   2404.7           1  ...                     0   \n",
       "14           0   4827.9           0  ...                     0   \n",
       "15           0  10602.4           0  ...                     0   \n",
       "16           0  11073.2           1  ...                     0   \n",
       "17           1  15555.2           0  ...                     0   \n",
       "18           0   2709.2           1  ...                     0   \n",
       "19           0  11396.9           1  ...                     0   \n",
       "20           0   4827.9           0  ...                     0   \n",
       "\n",
       "    job_title_Labourer  job_title_Lawyer  job_title_Manager  \\\n",
       "0                    0                 0                  0   \n",
       "1                    0                 0                  0   \n",
       "2                    0                 0                  0   \n",
       "3                    0                 0                  0   \n",
       "4                    0                 0                  0   \n",
       "5                    0                 0                  0   \n",
       "6                    0                 0                  0   \n",
       "7                    0                 0                  0   \n",
       "9                    0                 0                  0   \n",
       "10                   0                 0                  0   \n",
       "11                   0                 0                  0   \n",
       "12                   0                 0                  0   \n",
       "13                   0                 0                  0   \n",
       "14                   0                 0                  0   \n",
       "15                   0                 0                  0   \n",
       "16                   0                 0                  0   \n",
       "17                   0                 0                  0   \n",
       "18                   0                 0                  0   \n",
       "19                   0                 0                  1   \n",
       "20                   0                 0                  0   \n",
       "\n",
       "    job_title_Photographer  job_title_Police  job_title_Politician  \\\n",
       "0                        0                 0                     0   \n",
       "1                        0                 0                     0   \n",
       "2                        0                 0                     0   \n",
       "3                        0                 0                     0   \n",
       "4                        0                 0                     0   \n",
       "5                        0                 0                     0   \n",
       "6                        0                 0                     0   \n",
       "7                        0                 0                     0   \n",
       "9                        0                 0                     0   \n",
       "10                       0                 1                     0   \n",
       "11                       0                 0                     0   \n",
       "12                       0                 0                     0   \n",
       "13                       0                 0                     0   \n",
       "14                       0                 0                     0   \n",
       "15                       0                 0                     0   \n",
       "16                       0                 0                     0   \n",
       "17                       0                 0                     0   \n",
       "18                       0                 0                     0   \n",
       "19                       0                 0                     0   \n",
       "20                       0                 0                     0   \n",
       "\n",
       "    job_title_Singer  job_title_Student  job_title_Technician  \n",
       "0                  0                  0                     0  \n",
       "1                  0                  0                     0  \n",
       "2                  0                  0                     0  \n",
       "3                  0                  0                     0  \n",
       "4                  0                  0                     0  \n",
       "5                  0                  0                     0  \n",
       "6                  1                  0                     0  \n",
       "7                  0                  0                     0  \n",
       "9                  0                  0                     0  \n",
       "10                 0                  0                     0  \n",
       "11                 0                  0                     0  \n",
       "12                 0                  1                     0  \n",
       "13                 1                  0                     0  \n",
       "14                 0                  0                     0  \n",
       "15                 0                  0                     0  \n",
       "16                 0                  0                     0  \n",
       "17                 1                  0                     0  \n",
       "18                 0                  1                     0  \n",
       "19                 0                  0                     0  \n",
       "20                 0                  0                     0  \n",
       "\n",
       "[20 rows x 147 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of features: 146\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>no_of_dependents</th>\n",
       "      <th>smoker</th>\n",
       "      <th>bloodpressure</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>regular_ex</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>...</th>\n",
       "      <th>job_title_Journalist</th>\n",
       "      <th>job_title_Labourer</th>\n",
       "      <th>job_title_Lawyer</th>\n",
       "      <th>job_title_Manager</th>\n",
       "      <th>job_title_Photographer</th>\n",
       "      <th>job_title_Police</th>\n",
       "      <th>job_title_Politician</th>\n",
       "      <th>job_title_Singer</th>\n",
       "      <th>job_title_Student</th>\n",
       "      <th>job_title_Technician</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>64</td>\n",
       "      <td>24.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.0</td>\n",
       "      <td>75</td>\n",
       "      <td>22.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>64</td>\n",
       "      <td>17.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.0</td>\n",
       "      <td>53</td>\n",
       "      <td>36.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>50</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  weight   bmi  no_of_dependents  smoker  bloodpressure  diabetes  \\\n",
       "0  60.0      64  24.3                 1       0             72         0   \n",
       "1  49.0      75  22.6                 1       0             78         1   \n",
       "2  32.0      64  17.8                 2       1             88         1   \n",
       "3  61.0      53  36.4                 1       1             72         1   \n",
       "4  19.0      50  20.6                 0       0             82         1   \n",
       "\n",
       "   regular_ex  sex_female  sex_male  ...  job_title_Journalist  \\\n",
       "0           0           0         1  ...                     0   \n",
       "1           1           1         0  ...                     0   \n",
       "2           1           1         0  ...                     0   \n",
       "3           0           1         0  ...                     0   \n",
       "4           0           1         0  ...                     0   \n",
       "\n",
       "   job_title_Labourer  job_title_Lawyer  job_title_Manager  \\\n",
       "0                   0                 0                  0   \n",
       "1                   0                 0                  0   \n",
       "2                   0                 0                  0   \n",
       "3                   0                 0                  0   \n",
       "4                   0                 0                  0   \n",
       "\n",
       "   job_title_Photographer  job_title_Police  job_title_Politician  \\\n",
       "0                       0                 0                     0   \n",
       "1                       0                 0                     0   \n",
       "2                       0                 0                     0   \n",
       "3                       0                 0                     0   \n",
       "4                       0                 0                     0   \n",
       "\n",
       "   job_title_Singer  job_title_Student  job_title_Technician  \n",
       "0                 0                  0                     0  \n",
       "1                 0                  0                     0  \n",
       "2                 0                  0                     0  \n",
       "3                 0                  0                     0  \n",
       "4                 0                  0                     0  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocess data\n",
    "X = data.drop('claim', axis=1)\n",
    "num_columns = X.shape[1]\n",
    "print(\"num of features: \" + str(num_columns))\n",
    "y = data['claim']\n",
    "X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.89546079 -0.3409248  -0.1684676  ... -0.23252521 -0.2985288\n",
      "  -0.13845047]\n",
      " [-0.39847008  0.91004049 -0.15224112 ... -0.23252521 -0.2985288\n",
      "  -0.13845047]\n",
      " [ 0.87950603  1.13079907  2.83343038 ... -0.23252521 -0.2985288\n",
      "  -0.13845047]\n",
      " ...\n",
      " [-0.6114661  -1.5183039  -0.72016776 ... -0.23252521 -0.2985288\n",
      "  -0.13845047]\n",
      " [ 0.45351399 -0.12016622  0.5617238  ... -0.23252521 -0.2985288\n",
      "  -0.13845047]\n",
      " [ 1.37649674 -0.92961435 -0.2333735  ... -0.23252521 -0.2985288\n",
      "  -0.13845047]]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=69)\n",
    "# Second split: Split the 40% temporary set into 25% test and 15% evaluation\n",
    "X_eval, X_test, y_eval, y_test = train_test_split(X_temp, y_temp, test_size=(0.25/0.4), random_state=69)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "#load scaler \n",
    "scaler = joblib.load('scaler.pkl')\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_eval_scaled = scaler.transform(X_eval)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kobra\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Sequential.add() got an unexpected keyword argument 'kernel_regularizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 59\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# For each set of parameters\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m param_list:\n\u001b[0;32m     57\u001b[0m \n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# Create a model\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 13\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(hidden_layers, neurons, optimizer, learning_rate, regularization)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(hidden_layers, neurons, optimizer, learning_rate, regularization):\n\u001b[0;32m     12\u001b[0m     model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneurons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregularizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregularization\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLeakyReLU(neurons), kernel_regularizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mregularizers\u001b[38;5;241m.\u001b[39ml2(regularization))\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(hidden_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: Sequential.add() got an unexpected keyword argument 'kernel_regularizer'"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume X and y are defined somewhere above this code\n",
    "input_dim = X.shape[1]\n",
    "\n",
    "# Define your TensorFlow ANN model\n",
    "def create_model(hidden_layers, neurons, optimizer, learning_rate, regularization):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(neurons, input_shape=(input_dim,)), kernel_regularizer=tf.keras.regularizers.l2(regularization))\n",
    "    model.add(tf.keras.layers.LeakyReLU(neurons), kernel_regularizer=tf.keras.regularizers.l2(regularization))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(tf.keras.layers.Dense(neurons), kernel_regularizer=tf.keras.regularizers.l2(regularization))\n",
    "        model.add(tf.keras.layers.LeakyReLU(), kernel_regularizer=tf.keras.regularizers.l2(regularization))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='linear'), kernel_regularizer=tf.keras.regularizers.l2(regularization))\n",
    "    \n",
    "    if optimizer == 'adamW':\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'Adadelta':\n",
    "        optimizer = tf.keras.optimizers.Adadelta(learning_rate=learning_rate)\n",
    "    elif optimizer == 'Adagrad':\n",
    "        optimizer = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "    elif optimizer == 'Adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'Adamax':\n",
    "        optimizer = tf.keras.optimizers.Adamax(learning_rate=learning_rate)\n",
    "    elif optimizer == 'Nadam':\n",
    "        optimizer = tf.keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae', tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsolutePercentageError()])\n",
    "    return model\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'hidden_layers': [4,5, 6, 7, 8, 9, 10 ,11, 12,13,14,15,16], \n",
    "    'neurons': [3, 5, 6, 7, 8, 9, 10,11, 12,13,14,15,16], \n",
    "    'optimizer': ['adamW', 'Adadelta', 'Adagrad', 'Adam', 'Adamax', 'Nadam', 'RMSprop'],\n",
    "    'learning_rate': [0.001, 0.01,0.1],\n",
    "    'regularization': [0.01, 0.01,0.1]\n",
    "}\n",
    "\n",
    "# Create a ParameterSampler\n",
    "param_list = list(ParameterSampler(param_grid, n_iter=300, random_state=69))\n",
    "best_score = np.inf\n",
    "best_scores = None\n",
    "best_params = None\n",
    "\n",
    "# For each set of parameters\n",
    "for params in param_list:\n",
    "\n",
    "    # Create a model\n",
    "    model = create_model(**params)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train, epochs=150, batch_size=64, verbose=0)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(X_eval_scaled, y_eval, verbose=0)\n",
    "    print(score)\n",
    "    print(params)\n",
    "\n",
    "    \n",
    "    if score[0] < best_score:\n",
    "        best_score = score[0]\n",
    "        best_params = params\n",
    "        best_scores = score\n",
    "\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Score: \", best_score)\n",
    "print(best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'regularization': 0.01, 'optimizer': 'Adamax', 'neurons': 16, 'learning_rate': 0.1, 'hidden_layers': 16}\n",
      "Best Score:  12743031.0\n",
      "[12743031.0, 1836.1156005859375, 3569.73828125, 19.719820022583008]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Score: \", best_score)\n",
    "print(best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kobra\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 657823680.0000 - mae: 15564.2500 - mean_absolute_percentage_error: 140.1449 - root_mean_squared_error: 24682.1250\n",
      "Epoch 2/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 272541952.0000 - mae: 11819.7256 - mean_absolute_percentage_error: 99.6629 - root_mean_squared_error: 16388.6816\n",
      "Epoch 3/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 37517260.0000 - mae: 4264.3623 - mean_absolute_percentage_error: 52.8963 - root_mean_squared_error: 6123.3789\n",
      "Epoch 4/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32191430.0000 - mae: 3819.3311 - mean_absolute_percentage_error: 46.0942 - root_mean_squared_error: 5670.8257\n",
      "Epoch 5/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30832932.0000 - mae: 3697.6697 - mean_absolute_percentage_error: 43.2836 - root_mean_squared_error: 5547.6992\n",
      "Epoch 6/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 30256204.0000 - mae: 3715.0090 - mean_absolute_percentage_error: 43.7541 - root_mean_squared_error: 5497.0142\n",
      "Epoch 7/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 27346940.0000 - mae: 3421.5037 - mean_absolute_percentage_error: 38.7882 - root_mean_squared_error: 5225.6919\n",
      "Epoch 8/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 28481866.0000 - mae: 3500.1025 - mean_absolute_percentage_error: 40.1962 - root_mean_squared_error: 5330.1030\n",
      "Epoch 9/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 25288744.0000 - mae: 3259.8643 - mean_absolute_percentage_error: 38.6045 - root_mean_squared_error: 5027.4146\n",
      "Epoch 10/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 25029556.0000 - mae: 3292.9514 - mean_absolute_percentage_error: 37.7979 - root_mean_squared_error: 4999.5347\n",
      "Epoch 11/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23251846.0000 - mae: 3127.0520 - mean_absolute_percentage_error: 37.1078 - root_mean_squared_error: 4816.3711\n",
      "Epoch 12/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 23101282.0000 - mae: 3183.5317 - mean_absolute_percentage_error: 38.4684 - root_mean_squared_error: 4805.1274\n",
      "Epoch 13/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29238236.0000 - mae: 3531.9575 - mean_absolute_percentage_error: 39.7447 - root_mean_squared_error: 5394.4561\n",
      "Epoch 14/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22239352.0000 - mae: 3057.0969 - mean_absolute_percentage_error: 36.1251 - root_mean_squared_error: 4714.0815\n",
      "Epoch 15/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23803872.0000 - mae: 3176.1985 - mean_absolute_percentage_error: 36.0132 - root_mean_squared_error: 4877.0815\n",
      "Epoch 16/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22518436.0000 - mae: 3094.4932 - mean_absolute_percentage_error: 35.3668 - root_mean_squared_error: 4744.7290\n",
      "Epoch 17/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22599664.0000 - mae: 3164.9639 - mean_absolute_percentage_error: 36.1660 - root_mean_squared_error: 4750.1899\n",
      "Epoch 18/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 20902110.0000 - mae: 2999.7275 - mean_absolute_percentage_error: 35.4443 - root_mean_squared_error: 4570.4912\n",
      "Epoch 19/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 23562212.0000 - mae: 3280.8281 - mean_absolute_percentage_error: 37.6823 - root_mean_squared_error: 4853.0835\n",
      "Epoch 20/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19754760.0000 - mae: 2843.5598 - mean_absolute_percentage_error: 33.0770 - root_mean_squared_error: 4443.5713\n",
      "Epoch 21/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 20169386.0000 - mae: 2937.0706 - mean_absolute_percentage_error: 35.6549 - root_mean_squared_error: 4489.6216\n",
      "Epoch 22/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19020772.0000 - mae: 2876.9355 - mean_absolute_percentage_error: 35.1490 - root_mean_squared_error: 4356.3340\n",
      "Epoch 23/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18689982.0000 - mae: 2818.7539 - mean_absolute_percentage_error: 34.5752 - root_mean_squared_error: 4321.9717\n",
      "Epoch 24/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19724248.0000 - mae: 2900.2251 - mean_absolute_percentage_error: 34.2471 - root_mean_squared_error: 4439.0615\n",
      "Epoch 25/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18453208.0000 - mae: 2837.9194 - mean_absolute_percentage_error: 35.9783 - root_mean_squared_error: 4294.5264\n",
      "Epoch 26/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 17443730.0000 - mae: 2747.9832 - mean_absolute_percentage_error: 34.6730 - root_mean_squared_error: 4175.1704\n",
      "Epoch 27/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18023634.0000 - mae: 2806.3860 - mean_absolute_percentage_error: 35.3497 - root_mean_squared_error: 4244.6704\n",
      "Epoch 28/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16604032.0000 - mae: 2650.8530 - mean_absolute_percentage_error: 33.8834 - root_mean_squared_error: 4072.3950\n",
      "Epoch 29/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 17761356.0000 - mae: 2822.8291 - mean_absolute_percentage_error: 35.7313 - root_mean_squared_error: 4213.8340\n",
      "Epoch 30/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15537959.0000 - mae: 2587.5190 - mean_absolute_percentage_error: 33.8108 - root_mean_squared_error: 3939.1614\n",
      "Epoch 31/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15685425.0000 - mae: 2598.5862 - mean_absolute_percentage_error: 33.8176 - root_mean_squared_error: 3957.8591\n",
      "Epoch 32/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16146854.0000 - mae: 2644.4307 - mean_absolute_percentage_error: 32.7504 - root_mean_squared_error: 4015.0608\n",
      "Epoch 33/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 16811234.0000 - mae: 2625.5378 - mean_absolute_percentage_error: 34.3719 - root_mean_squared_error: 4098.9727\n",
      "Epoch 34/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14809370.0000 - mae: 2540.3567 - mean_absolute_percentage_error: 31.8240 - root_mean_squared_error: 3846.1328\n",
      "Epoch 35/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15719581.0000 - mae: 2560.7209 - mean_absolute_percentage_error: 32.5105 - root_mean_squared_error: 3960.1724\n",
      "Epoch 36/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13882880.0000 - mae: 2430.2769 - mean_absolute_percentage_error: 31.7126 - root_mean_squared_error: 3724.3157\n",
      "Epoch 37/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15149749.0000 - mae: 2554.6980 - mean_absolute_percentage_error: 32.7218 - root_mean_squared_error: 3891.1416\n",
      "Epoch 38/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13039217.0000 - mae: 2381.6838 - mean_absolute_percentage_error: 31.2808 - root_mean_squared_error: 3607.5249\n",
      "Epoch 39/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13549084.0000 - mae: 2382.8464 - mean_absolute_percentage_error: 32.1276 - root_mean_squared_error: 3680.1775\n",
      "Epoch 40/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14892435.0000 - mae: 2494.1628 - mean_absolute_percentage_error: 31.0486 - root_mean_squared_error: 3854.7539\n",
      "Epoch 41/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13649176.0000 - mae: 2415.3391 - mean_absolute_percentage_error: 30.9717 - root_mean_squared_error: 3693.5085\n",
      "Epoch 42/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11576452.0000 - mae: 2242.1199 - mean_absolute_percentage_error: 28.9133 - root_mean_squared_error: 3400.7263\n",
      "Epoch 43/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11912786.0000 - mae: 2207.0039 - mean_absolute_percentage_error: 29.2287 - root_mean_squared_error: 3442.7722\n",
      "Epoch 44/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11822222.0000 - mae: 2226.5806 - mean_absolute_percentage_error: 27.4824 - root_mean_squared_error: 3433.0222\n",
      "Epoch 45/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11502884.0000 - mae: 2196.7620 - mean_absolute_percentage_error: 26.6955 - root_mean_squared_error: 3389.9131\n",
      "Epoch 46/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12294890.0000 - mae: 2296.9199 - mean_absolute_percentage_error: 29.0010 - root_mean_squared_error: 3505.0774\n",
      "Epoch 47/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11397680.0000 - mae: 2235.3625 - mean_absolute_percentage_error: 28.4606 - root_mean_squared_error: 3374.2625\n",
      "Epoch 48/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10892598.0000 - mae: 2129.8203 - mean_absolute_percentage_error: 27.2984 - root_mean_squared_error: 3296.5535\n",
      "Epoch 49/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10084646.0000 - mae: 2089.6650 - mean_absolute_percentage_error: 27.6648 - root_mean_squared_error: 3172.5842\n",
      "Epoch 50/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10818586.0000 - mae: 2181.5479 - mean_absolute_percentage_error: 27.2289 - root_mean_squared_error: 3285.0415\n",
      "Epoch 51/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 10619158.0000 - mae: 2089.1589 - mean_absolute_percentage_error: 27.4251 - root_mean_squared_error: 3257.5264\n",
      "Epoch 52/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9936226.0000 - mae: 2041.1552 - mean_absolute_percentage_error: 26.5386 - root_mean_squared_error: 3151.4385\n",
      "Epoch 53/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9765925.0000 - mae: 2040.8157 - mean_absolute_percentage_error: 27.4210 - root_mean_squared_error: 3123.8020\n",
      "Epoch 54/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9789543.0000 - mae: 2053.9758 - mean_absolute_percentage_error: 26.8271 - root_mean_squared_error: 3126.8459\n",
      "Epoch 55/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8815787.0000 - mae: 1934.1383 - mean_absolute_percentage_error: 25.4861 - root_mean_squared_error: 2967.0510\n",
      "Epoch 56/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9014759.0000 - mae: 1973.6046 - mean_absolute_percentage_error: 25.6599 - root_mean_squared_error: 3000.3455\n",
      "Epoch 57/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10217625.0000 - mae: 2134.5615 - mean_absolute_percentage_error: 27.2545 - root_mean_squared_error: 3196.0962\n",
      "Epoch 58/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9158713.0000 - mae: 1952.5272 - mean_absolute_percentage_error: 26.0982 - root_mean_squared_error: 3024.5537\n",
      "Epoch 59/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9435717.0000 - mae: 2014.6300 - mean_absolute_percentage_error: 24.8384 - root_mean_squared_error: 3070.7769\n",
      "Epoch 60/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9920264.0000 - mae: 2104.4890 - mean_absolute_percentage_error: 27.3168 - root_mean_squared_error: 3146.8923 \n",
      "Epoch 61/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8017410.5000 - mae: 1867.0752 - mean_absolute_percentage_error: 24.8326 - root_mean_squared_error: 2829.0193\n",
      "Epoch 62/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8233869.5000 - mae: 1837.8206 - mean_absolute_percentage_error: 23.8273 - root_mean_squared_error: 2868.5913\n",
      "Epoch 63/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8110395.5000 - mae: 1835.3827 - mean_absolute_percentage_error: 22.8771 - root_mean_squared_error: 2846.5593\n",
      "Epoch 64/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8701897.0000 - mae: 1880.5270 - mean_absolute_percentage_error: 24.3142 - root_mean_squared_error: 2946.8884\n",
      "Epoch 65/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7404982.0000 - mae: 1765.3007 - mean_absolute_percentage_error: 23.1869 - root_mean_squared_error: 2719.2092\n",
      "Epoch 66/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7611136.0000 - mae: 1757.2046 - mean_absolute_percentage_error: 23.3628 - root_mean_squared_error: 2757.9053\n",
      "Epoch 67/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8251576.0000 - mae: 1891.4203 - mean_absolute_percentage_error: 24.3104 - root_mean_squared_error: 2871.8896\n",
      "Epoch 68/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7257755.0000 - mae: 1728.4402 - mean_absolute_percentage_error: 22.4925 - root_mean_squared_error: 2690.5742\n",
      "Epoch 69/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7161581.5000 - mae: 1736.0326 - mean_absolute_percentage_error: 22.7512 - root_mean_squared_error: 2672.8955\n",
      "Epoch 70/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9494514.0000 - mae: 2005.0942 - mean_absolute_percentage_error: 25.5560 - root_mean_squared_error: 3079.1387\n",
      "Epoch 71/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7280102.0000 - mae: 1715.9827 - mean_absolute_percentage_error: 23.0024 - root_mean_squared_error: 2696.5530\n",
      "Epoch 72/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8987628.0000 - mae: 1901.7729 - mean_absolute_percentage_error: 23.8805 - root_mean_squared_error: 2978.5381\n",
      "Epoch 73/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8132463.5000 - mae: 1863.5393 - mean_absolute_percentage_error: 23.9438 - root_mean_squared_error: 2851.2451\n",
      "Epoch 74/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6664925.5000 - mae: 1686.0983 - mean_absolute_percentage_error: 22.7761 - root_mean_squared_error: 2578.5725\n",
      "Epoch 75/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8853942.0000 - mae: 1920.5828 - mean_absolute_percentage_error: 23.2391 - root_mean_squared_error: 2972.6997\n",
      "Epoch 76/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7529068.5000 - mae: 1778.6095 - mean_absolute_percentage_error: 24.3322 - root_mean_squared_error: 2742.0430\n",
      "Epoch 77/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6665057.5000 - mae: 1672.2141 - mean_absolute_percentage_error: 21.3672 - root_mean_squared_error: 2580.8667\n",
      "Epoch 78/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6698729.5000 - mae: 1685.4580 - mean_absolute_percentage_error: 22.6010 - root_mean_squared_error: 2587.2825\n",
      "Epoch 79/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6170411.0000 - mae: 1625.2480 - mean_absolute_percentage_error: 22.0799 - root_mean_squared_error: 2479.5322\n",
      "Epoch 80/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5846270.5000 - mae: 1585.8706 - mean_absolute_percentage_error: 21.1041 - root_mean_squared_error: 2413.9556\n",
      "Epoch 81/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6653361.0000 - mae: 1718.4495 - mean_absolute_percentage_error: 22.3173 - root_mean_squared_error: 2578.6584\n",
      "Epoch 82/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8644380.0000 - mae: 1926.5613 - mean_absolute_percentage_error: 26.0640 - root_mean_squared_error: 2928.0806\n",
      "Epoch 83/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8127335.0000 - mae: 1878.5408 - mean_absolute_percentage_error: 23.6297 - root_mean_squared_error: 2850.2754\n",
      "Epoch 84/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6146354.5000 - mae: 1598.2252 - mean_absolute_percentage_error: 20.7850 - root_mean_squared_error: 2476.9719\n",
      "Epoch 85/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7179993.5000 - mae: 1739.0024 - mean_absolute_percentage_error: 21.0219 - root_mean_squared_error: 2679.0759\n",
      "Epoch 86/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5999463.5000 - mae: 1584.6840 - mean_absolute_percentage_error: 20.8130 - root_mean_squared_error: 2448.2798\n",
      "Epoch 87/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7513217.0000 - mae: 1788.7021 - mean_absolute_percentage_error: 23.7965 - root_mean_squared_error: 2732.0215\n",
      "Epoch 88/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6162790.0000 - mae: 1637.3842 - mean_absolute_percentage_error: 21.1670 - root_mean_squared_error: 2481.7222\n",
      "Epoch 89/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6107449.0000 - mae: 1608.6920 - mean_absolute_percentage_error: 22.0224 - root_mean_squared_error: 2468.3955\n",
      "Epoch 90/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7322463.0000 - mae: 1767.0601 - mean_absolute_percentage_error: 21.7078 - root_mean_squared_error: 2702.5696\n",
      "Epoch 91/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7923105.0000 - mae: 1820.9178 - mean_absolute_percentage_error: 24.1586 - root_mean_squared_error: 2813.0203\n",
      "Epoch 92/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6904660.5000 - mae: 1705.5435 - mean_absolute_percentage_error: 21.4458 - root_mean_squared_error: 2625.5369\n",
      "Epoch 93/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5632535.0000 - mae: 1576.9451 - mean_absolute_percentage_error: 20.8745 - root_mean_squared_error: 2371.3484\n",
      "Epoch 94/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7156204.5000 - mae: 1774.0278 - mean_absolute_percentage_error: 22.2587 - root_mean_squared_error: 2674.5100\n",
      "Epoch 95/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7513195.5000 - mae: 1788.5504 - mean_absolute_percentage_error: 24.0125 - root_mean_squared_error: 2739.5339\n",
      "Epoch 96/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5689592.0000 - mae: 1530.2706 - mean_absolute_percentage_error: 19.7756 - root_mean_squared_error: 2384.5837\n",
      "Epoch 97/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5043940.5000 - mae: 1466.7904 - mean_absolute_percentage_error: 19.5233 - root_mean_squared_error: 2244.2085\n",
      "Epoch 98/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5992526.5000 - mae: 1601.0533 - mean_absolute_percentage_error: 22.5244 - root_mean_squared_error: 2446.8030\n",
      "Epoch 99/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6006791.5000 - mae: 1592.2059 - mean_absolute_percentage_error: 20.7062 - root_mean_squared_error: 2447.6252\n",
      "Epoch 100/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5469762.0000 - mae: 1523.5770 - mean_absolute_percentage_error: 20.0145 - root_mean_squared_error: 2338.0129\n",
      "Epoch 101/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5190318.5000 - mae: 1490.3127 - mean_absolute_percentage_error: 19.6992 - root_mean_squared_error: 2276.0469\n",
      "Epoch 102/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6819614.0000 - mae: 1664.3715 - mean_absolute_percentage_error: 21.3997 - root_mean_squared_error: 2609.2161\n",
      "Epoch 103/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5365770.5000 - mae: 1496.8011 - mean_absolute_percentage_error: 20.0704 - root_mean_squared_error: 2312.1758\n",
      "Epoch 104/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5616873.5000 - mae: 1539.9532 - mean_absolute_percentage_error: 20.8970 - root_mean_squared_error: 2368.3899\n",
      "Epoch 105/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5376427.0000 - mae: 1483.5282 - mean_absolute_percentage_error: 18.9820 - root_mean_squared_error: 2318.2891\n",
      "Epoch 106/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5080427.0000 - mae: 1496.6677 - mean_absolute_percentage_error: 19.6190 - root_mean_squared_error: 2251.8823\n",
      "Epoch 107/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5866331.0000 - mae: 1568.6866 - mean_absolute_percentage_error: 20.4008 - root_mean_squared_error: 2421.6643\n",
      "Epoch 108/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4885360.5000 - mae: 1433.3226 - mean_absolute_percentage_error: 18.9372 - root_mean_squared_error: 2209.8650\n",
      "Epoch 109/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5718261.5000 - mae: 1580.6509 - mean_absolute_percentage_error: 20.8928 - root_mean_squared_error: 2390.2964\n",
      "Epoch 110/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5654998.5000 - mae: 1584.5530 - mean_absolute_percentage_error: 21.0865 - root_mean_squared_error: 2377.3528\n",
      "Epoch 111/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7269320.0000 - mae: 1750.5931 - mean_absolute_percentage_error: 21.7949 - root_mean_squared_error: 2693.4946\n",
      "Epoch 112/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4264278.5000 - mae: 1351.8278 - mean_absolute_percentage_error: 17.5396 - root_mean_squared_error: 2063.9038\n",
      "Epoch 113/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4706634.0000 - mae: 1419.9786 - mean_absolute_percentage_error: 19.0177 - root_mean_squared_error: 2168.0764\n",
      "Epoch 114/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5328385.0000 - mae: 1505.7104 - mean_absolute_percentage_error: 19.7931 - root_mean_squared_error: 2304.3291\n",
      "Epoch 115/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5199438.0000 - mae: 1485.6743 - mean_absolute_percentage_error: 18.8502 - root_mean_squared_error: 2279.4294\n",
      "Epoch 116/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5931628.5000 - mae: 1642.4547 - mean_absolute_percentage_error: 21.9277 - root_mean_squared_error: 2435.0957\n",
      "Epoch 117/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5453990.5000 - mae: 1560.8115 - mean_absolute_percentage_error: 22.0328 - root_mean_squared_error: 2334.7231\n",
      "Epoch 118/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4846206.0000 - mae: 1422.1519 - mean_absolute_percentage_error: 19.3481 - root_mean_squared_error: 2199.8777\n",
      "Epoch 119/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5402742.0000 - mae: 1527.2852 - mean_absolute_percentage_error: 20.5506 - root_mean_squared_error: 2322.9766\n",
      "Epoch 120/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5276196.0000 - mae: 1523.1040 - mean_absolute_percentage_error: 20.5704 - root_mean_squared_error: 2295.6882\n",
      "Epoch 121/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4613532.5000 - mae: 1410.4883 - mean_absolute_percentage_error: 19.1221 - root_mean_squared_error: 2146.6616\n",
      "Epoch 122/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4638249.0000 - mae: 1390.1163 - mean_absolute_percentage_error: 18.7240 - root_mean_squared_error: 2149.3972\n",
      "Epoch 123/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4399651.0000 - mae: 1375.9050 - mean_absolute_percentage_error: 18.7961 - root_mean_squared_error: 2097.2429\n",
      "Epoch 124/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3892520.5000 - mae: 1302.6964 - mean_absolute_percentage_error: 17.2737 - root_mean_squared_error: 1972.3231\n",
      "Epoch 125/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4730588.5000 - mae: 1417.3555 - mean_absolute_percentage_error: 18.2423 - root_mean_squared_error: 2174.2471\n",
      "Epoch 126/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5931481.5000 - mae: 1574.3671 - mean_absolute_percentage_error: 19.3664 - root_mean_squared_error: 2434.5315\n",
      "Epoch 127/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5249867.0000 - mae: 1523.5571 - mean_absolute_percentage_error: 19.7334 - root_mean_squared_error: 2290.9202\n",
      "Epoch 128/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5592003.5000 - mae: 1559.3593 - mean_absolute_percentage_error: 20.2682 - root_mean_squared_error: 2363.8677\n",
      "Epoch 129/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5074575.5000 - mae: 1487.5116 - mean_absolute_percentage_error: 19.0147 - root_mean_squared_error: 2247.7451\n",
      "Epoch 130/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4858226.5000 - mae: 1431.2437 - mean_absolute_percentage_error: 18.5566 - root_mean_squared_error: 2200.5781\n",
      "Epoch 131/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5996122.0000 - mae: 1599.1763 - mean_absolute_percentage_error: 21.0423 - root_mean_squared_error: 2447.3499\n",
      "Epoch 132/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4235249.0000 - mae: 1363.0103 - mean_absolute_percentage_error: 17.5809 - root_mean_squared_error: 2057.2966\n",
      "Epoch 133/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3883867.7500 - mae: 1286.4279 - mean_absolute_percentage_error: 17.3956 - root_mean_squared_error: 1965.8989\n",
      "Epoch 134/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5592303.0000 - mae: 1553.2319 - mean_absolute_percentage_error: 19.4620 - root_mean_squared_error: 2364.0352\n",
      "Epoch 135/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4294482.0000 - mae: 1347.8658 - mean_absolute_percentage_error: 18.0182 - root_mean_squared_error: 2070.3591\n",
      "Epoch 136/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3691002.0000 - mae: 1234.4574 - mean_absolute_percentage_error: 16.9915 - root_mean_squared_error: 1918.7521\n",
      "Epoch 137/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3549100.5000 - mae: 1239.3143 - mean_absolute_percentage_error: 16.1162 - root_mean_squared_error: 1881.0940\n",
      "Epoch 138/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3513621.2500 - mae: 1246.6493 - mean_absolute_percentage_error: 16.6295 - root_mean_squared_error: 1870.4972\n",
      "Epoch 139/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4351621.0000 - mae: 1370.5488 - mean_absolute_percentage_error: 18.5667 - root_mean_squared_error: 2084.5615\n",
      "Epoch 140/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4654937.5000 - mae: 1423.4667 - mean_absolute_percentage_error: 19.6786 - root_mean_squared_error: 2156.7095\n",
      "Epoch 141/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4526061.0000 - mae: 1409.7589 - mean_absolute_percentage_error: 19.0098 - root_mean_squared_error: 2126.4663\n",
      "Epoch 142/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4241065.0000 - mae: 1325.0499 - mean_absolute_percentage_error: 17.1496 - root_mean_squared_error: 2058.4778\n",
      "Epoch 143/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3415498.5000 - mae: 1207.1614 - mean_absolute_percentage_error: 16.4314 - root_mean_squared_error: 1844.3463\n",
      "Epoch 144/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4522409.0000 - mae: 1396.7997 - mean_absolute_percentage_error: 18.2005 - root_mean_squared_error: 2122.0237\n",
      "Epoch 145/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3892346.0000 - mae: 1269.4425 - mean_absolute_percentage_error: 16.7674 - root_mean_squared_error: 1970.9733\n",
      "Epoch 146/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3746757.5000 - mae: 1268.1777 - mean_absolute_percentage_error: 16.8377 - root_mean_squared_error: 1935.3110\n",
      "Epoch 147/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3672296.0000 - mae: 1244.3292 - mean_absolute_percentage_error: 16.5011 - root_mean_squared_error: 1914.3639\n",
      "Epoch 148/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4287287.5000 - mae: 1340.6705 - mean_absolute_percentage_error: 17.4852 - root_mean_squared_error: 2069.9338\n",
      "Epoch 149/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3696692.5000 - mae: 1277.8889 - mean_absolute_percentage_error: 16.7710 - root_mean_squared_error: 1920.5129\n",
      "Epoch 150/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4041387.5000 - mae: 1304.9912 - mean_absolute_percentage_error: 17.2949 - root_mean_squared_error: 2009.4690\n",
      "Epoch 151/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4868000.5000 - mae: 1457.9548 - mean_absolute_percentage_error: 18.7902 - root_mean_squared_error: 2205.1333\n",
      "Epoch 152/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3615499.0000 - mae: 1253.2655 - mean_absolute_percentage_error: 16.2631 - root_mean_squared_error: 1898.3529\n",
      "Epoch 153/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3894304.5000 - mae: 1294.2285 - mean_absolute_percentage_error: 17.0817 - root_mean_squared_error: 1970.7623\n",
      "Epoch 154/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3969336.5000 - mae: 1326.4941 - mean_absolute_percentage_error: 17.9566 - root_mean_squared_error: 1990.6136\n",
      "Epoch 155/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4415613.0000 - mae: 1372.9430 - mean_absolute_percentage_error: 17.5363 - root_mean_squared_error: 2101.1482\n",
      "Epoch 156/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4090957.7500 - mae: 1326.6737 - mean_absolute_percentage_error: 17.1732 - root_mean_squared_error: 2021.7529\n",
      "Epoch 157/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4041269.5000 - mae: 1306.3600 - mean_absolute_percentage_error: 17.1754 - root_mean_squared_error: 2009.4828\n",
      "Epoch 158/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3785755.5000 - mae: 1275.9994 - mean_absolute_percentage_error: 16.8541 - root_mean_squared_error: 1937.6243\n",
      "Epoch 159/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5021236.0000 - mae: 1463.3772 - mean_absolute_percentage_error: 19.9101 - root_mean_squared_error: 2237.2024\n",
      "Epoch 160/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3761826.5000 - mae: 1261.2084 - mean_absolute_percentage_error: 16.5806 - root_mean_squared_error: 1938.8239\n",
      "Epoch 161/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3665000.5000 - mae: 1257.6649 - mean_absolute_percentage_error: 16.8398 - root_mean_squared_error: 1913.5770\n",
      "Epoch 162/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3665136.7500 - mae: 1249.2415 - mean_absolute_percentage_error: 16.6064 - root_mean_squared_error: 1912.4805\n",
      "Epoch 163/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4319853.0000 - mae: 1336.8538 - mean_absolute_percentage_error: 18.0196 - root_mean_squared_error: 2076.3850\n",
      "Epoch 164/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3516698.0000 - mae: 1254.6549 - mean_absolute_percentage_error: 16.9125 - root_mean_squared_error: 1874.2606\n",
      "Epoch 165/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4008872.7500 - mae: 1352.5841 - mean_absolute_percentage_error: 17.7148 - root_mean_squared_error: 2001.0846\n",
      "Epoch 166/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4731994.0000 - mae: 1385.7505 - mean_absolute_percentage_error: 18.4973 - root_mean_squared_error: 2173.5046\n",
      "Epoch 167/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4029823.2500 - mae: 1339.1830 - mean_absolute_percentage_error: 18.1290 - root_mean_squared_error: 2007.1737\n",
      "Epoch 168/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3268246.7500 - mae: 1172.1769 - mean_absolute_percentage_error: 15.6241 - root_mean_squared_error: 1807.1566\n",
      "Epoch 169/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3390110.2500 - mae: 1218.9034 - mean_absolute_percentage_error: 15.8862 - root_mean_squared_error: 1838.9659\n",
      "Epoch 170/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3535615.0000 - mae: 1245.5754 - mean_absolute_percentage_error: 16.4512 - root_mean_squared_error: 1878.3330\n",
      "Epoch 171/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3036214.5000 - mae: 1145.1884 - mean_absolute_percentage_error: 15.6585 - root_mean_squared_error: 1741.4663\n",
      "Epoch 172/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3636132.0000 - mae: 1231.9104 - mean_absolute_percentage_error: 16.2786 - root_mean_squared_error: 1906.2035\n",
      "Epoch 173/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3197188.0000 - mae: 1166.0483 - mean_absolute_percentage_error: 15.2965 - root_mean_squared_error: 1787.1984\n",
      "Epoch 174/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3356811.7500 - mae: 1204.0586 - mean_absolute_percentage_error: 16.2212 - root_mean_squared_error: 1831.2502\n",
      "Epoch 175/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3887378.5000 - mae: 1319.0533 - mean_absolute_percentage_error: 16.7620 - root_mean_squared_error: 1970.1290\n",
      "Epoch 176/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3328788.2500 - mae: 1209.9465 - mean_absolute_percentage_error: 16.8306 - root_mean_squared_error: 1823.2322\n",
      "Epoch 177/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3456092.0000 - mae: 1253.1132 - mean_absolute_percentage_error: 16.7425 - root_mean_squared_error: 1857.5729\n",
      "Epoch 178/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4550823.5000 - mae: 1388.8280 - mean_absolute_percentage_error: 17.5496 - root_mean_squared_error: 2129.8562\n",
      "Epoch 179/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4440433.0000 - mae: 1377.9614 - mean_absolute_percentage_error: 17.1749 - root_mean_squared_error: 2104.5798\n",
      "Epoch 180/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3466836.5000 - mae: 1248.5586 - mean_absolute_percentage_error: 16.4714 - root_mean_squared_error: 1860.6279\n",
      "Epoch 181/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3520949.5000 - mae: 1231.9807 - mean_absolute_percentage_error: 16.1874 - root_mean_squared_error: 1876.0923\n",
      "Epoch 182/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4191016.0000 - mae: 1332.7433 - mean_absolute_percentage_error: 17.3882 - root_mean_squared_error: 2046.2267\n",
      "Epoch 183/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3346022.5000 - mae: 1212.3110 - mean_absolute_percentage_error: 15.3235 - root_mean_squared_error: 1828.6127\n",
      "Epoch 184/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3463446.5000 - mae: 1218.4092 - mean_absolute_percentage_error: 15.7799 - root_mean_squared_error: 1859.4913\n",
      "Epoch 185/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3528241.2500 - mae: 1233.1414 - mean_absolute_percentage_error: 16.1493 - root_mean_squared_error: 1875.9539\n",
      "Epoch 186/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3595796.2500 - mae: 1239.6348 - mean_absolute_percentage_error: 15.9133 - root_mean_squared_error: 1895.9855\n",
      "Epoch 187/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3654185.2500 - mae: 1253.3555 - mean_absolute_percentage_error: 16.1833 - root_mean_squared_error: 1909.8074\n",
      "Epoch 188/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3712667.2500 - mae: 1250.3641 - mean_absolute_percentage_error: 16.2036 - root_mean_squared_error: 1919.6501\n",
      "Epoch 189/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2938645.2500 - mae: 1148.1481 - mean_absolute_percentage_error: 15.7015 - root_mean_squared_error: 1709.7588\n",
      "Epoch 190/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3044239.2500 - mae: 1146.9501 - mean_absolute_percentage_error: 15.1842 - root_mean_squared_error: 1742.0863\n",
      "Epoch 191/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4258906.5000 - mae: 1360.3588 - mean_absolute_percentage_error: 16.5045 - root_mean_squared_error: 2061.0322\n",
      "Epoch 192/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3606502.0000 - mae: 1261.3636 - mean_absolute_percentage_error: 16.7554 - root_mean_squared_error: 1895.3376\n",
      "Epoch 193/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3744972.7500 - mae: 1286.8398 - mean_absolute_percentage_error: 16.6264 - root_mean_squared_error: 1934.2960\n",
      "Epoch 194/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3994483.7500 - mae: 1309.1392 - mean_absolute_percentage_error: 16.2802 - root_mean_squared_error: 1996.7056\n",
      "Epoch 195/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3175064.2500 - mae: 1174.0907 - mean_absolute_percentage_error: 15.4795 - root_mean_squared_error: 1780.1472\n",
      "Epoch 196/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3476258.5000 - mae: 1258.1707 - mean_absolute_percentage_error: 16.4231 - root_mean_squared_error: 1863.5425\n",
      "Epoch 197/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4026609.5000 - mae: 1343.4062 - mean_absolute_percentage_error: 16.9313 - root_mean_squared_error: 2005.1427\n",
      "Epoch 198/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3689051.2500 - mae: 1287.1943 - mean_absolute_percentage_error: 17.1707 - root_mean_squared_error: 1915.1743\n",
      "Epoch 199/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2893108.5000 - mae: 1108.2996 - mean_absolute_percentage_error: 14.5949 - root_mean_squared_error: 1695.5588\n",
      "Epoch 200/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2655405.5000 - mae: 1082.4493 - mean_absolute_percentage_error: 14.5405 - root_mean_squared_error: 1627.1006\n",
      "Epoch 201/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3610783.0000 - mae: 1226.8394 - mean_absolute_percentage_error: 15.6766 - root_mean_squared_error: 1897.0570\n",
      "Epoch 202/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3811697.2500 - mae: 1279.4183 - mean_absolute_percentage_error: 16.2993 - root_mean_squared_error: 1950.1384\n",
      "Epoch 203/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3886460.7500 - mae: 1307.5631 - mean_absolute_percentage_error: 17.2232 - root_mean_squared_error: 1969.7363\n",
      "Epoch 204/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2791260.5000 - mae: 1100.1622 - mean_absolute_percentage_error: 14.5787 - root_mean_squared_error: 1670.1187\n",
      "Epoch 205/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3366149.0000 - mae: 1195.2869 - mean_absolute_percentage_error: 15.7639 - root_mean_squared_error: 1833.3156\n",
      "Epoch 206/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2593001.7500 - mae: 1072.7518 - mean_absolute_percentage_error: 14.4932 - root_mean_squared_error: 1608.6406\n",
      "Epoch 207/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2639448.2500 - mae: 1082.3495 - mean_absolute_percentage_error: 14.4475 - root_mean_squared_error: 1617.3057\n",
      "Epoch 208/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3202792.7500 - mae: 1168.4668 - mean_absolute_percentage_error: 15.3416 - root_mean_squared_error: 1782.8409\n",
      "Epoch 209/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3762873.5000 - mae: 1232.2234 - mean_absolute_percentage_error: 15.9237 - root_mean_squared_error: 1938.6949\n",
      "Epoch 210/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4395834.0000 - mae: 1362.9742 - mean_absolute_percentage_error: 18.1136 - root_mean_squared_error: 2094.0352\n",
      "Epoch 211/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3614111.7500 - mae: 1224.9209 - mean_absolute_percentage_error: 15.8116 - root_mean_squared_error: 1899.7350\n",
      "Epoch 212/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3324773.2500 - mae: 1175.2217 - mean_absolute_percentage_error: 15.2269 - root_mean_squared_error: 1821.8947\n",
      "Epoch 213/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2626992.7500 - mae: 1073.1204 - mean_absolute_percentage_error: 14.4984 - root_mean_squared_error: 1618.0513\n",
      "Epoch 214/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3023108.2500 - mae: 1145.3234 - mean_absolute_percentage_error: 15.5805 - root_mean_squared_error: 1737.4069\n",
      "Epoch 215/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2905711.0000 - mae: 1119.2411 - mean_absolute_percentage_error: 14.7198 - root_mean_squared_error: 1702.9377\n",
      "Epoch 216/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2816345.0000 - mae: 1113.3856 - mean_absolute_percentage_error: 14.8999 - root_mean_squared_error: 1676.8690\n",
      "Epoch 217/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3169796.0000 - mae: 1173.7549 - mean_absolute_percentage_error: 15.2611 - root_mean_squared_error: 1775.5387\n",
      "Epoch 218/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2825450.5000 - mae: 1163.9366 - mean_absolute_percentage_error: 15.6471 - root_mean_squared_error: 1679.8868\n",
      "Epoch 219/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3272944.5000 - mae: 1199.5668 - mean_absolute_percentage_error: 15.4594 - root_mean_squared_error: 1807.4125\n",
      "Epoch 220/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3554960.5000 - mae: 1265.5496 - mean_absolute_percentage_error: 16.5447 - root_mean_squared_error: 1885.0796\n",
      "Epoch 221/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3447944.5000 - mae: 1224.0239 - mean_absolute_percentage_error: 15.7896 - root_mean_squared_error: 1855.2532\n",
      "Epoch 222/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2668026.5000 - mae: 1068.0403 - mean_absolute_percentage_error: 14.2374 - root_mean_squared_error: 1632.6469\n",
      "Epoch 223/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3095616.7500 - mae: 1152.1191 - mean_absolute_percentage_error: 14.9462 - root_mean_squared_error: 1758.8517\n",
      "Epoch 224/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3418507.0000 - mae: 1219.5132 - mean_absolute_percentage_error: 16.0617 - root_mean_squared_error: 1848.2484\n",
      "Epoch 225/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2887340.0000 - mae: 1149.7593 - mean_absolute_percentage_error: 14.7985 - root_mean_squared_error: 1698.0994\n",
      "Epoch 226/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3186941.7500 - mae: 1212.8025 - mean_absolute_percentage_error: 15.8517 - root_mean_squared_error: 1783.8118\n",
      "Epoch 227/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3137409.2500 - mae: 1174.6774 - mean_absolute_percentage_error: 14.9447 - root_mean_squared_error: 1770.9602\n",
      "Epoch 228/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3013095.7500 - mae: 1156.2728 - mean_absolute_percentage_error: 14.6059 - root_mean_squared_error: 1735.1346\n",
      "Epoch 229/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3250742.5000 - mae: 1191.7905 - mean_absolute_percentage_error: 15.1746 - root_mean_squared_error: 1800.0819\n",
      "Epoch 230/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3908297.0000 - mae: 1314.7842 - mean_absolute_percentage_error: 17.8988 - root_mean_squared_error: 1972.1741\n",
      "Epoch 231/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3185754.0000 - mae: 1186.3989 - mean_absolute_percentage_error: 15.1009 - root_mean_squared_error: 1783.8555\n",
      "Epoch 232/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2829087.5000 - mae: 1119.8152 - mean_absolute_percentage_error: 14.8214 - root_mean_squared_error: 1680.7748\n",
      "Epoch 233/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3156170.7500 - mae: 1168.6975 - mean_absolute_percentage_error: 14.7286 - root_mean_squared_error: 1773.7172\n",
      "Epoch 234/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2678215.2500 - mae: 1090.0510 - mean_absolute_percentage_error: 14.7279 - root_mean_squared_error: 1635.7233\n",
      "Epoch 235/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3717795.0000 - mae: 1256.1144 - mean_absolute_percentage_error: 15.1725 - root_mean_squared_error: 1924.3864\n",
      "Epoch 236/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3201445.5000 - mae: 1178.8801 - mean_absolute_percentage_error: 15.2773 - root_mean_squared_error: 1784.2848\n",
      "Epoch 237/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2861508.7500 - mae: 1129.2273 - mean_absolute_percentage_error: 14.9042 - root_mean_squared_error: 1691.2222\n",
      "Epoch 238/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2884369.7500 - mae: 1116.9375 - mean_absolute_percentage_error: 14.3805 - root_mean_squared_error: 1696.4778\n",
      "Epoch 239/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3769117.0000 - mae: 1318.3329 - mean_absolute_percentage_error: 16.7407 - root_mean_squared_error: 1939.2783\n",
      "Epoch 240/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3596829.7500 - mae: 1246.3132 - mean_absolute_percentage_error: 16.3168 - root_mean_squared_error: 1895.6656\n",
      "Epoch 241/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2982827.5000 - mae: 1159.5573 - mean_absolute_percentage_error: 16.2395 - root_mean_squared_error: 1726.2860\n",
      "Epoch 242/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2552852.7500 - mae: 1059.6820 - mean_absolute_percentage_error: 14.0071 - root_mean_squared_error: 1597.0562\n",
      "Epoch 243/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2509968.7500 - mae: 1065.1650 - mean_absolute_percentage_error: 13.9859 - root_mean_squared_error: 1583.6052\n",
      "Epoch 244/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2375333.5000 - mae: 1018.2341 - mean_absolute_percentage_error: 13.6062 - root_mean_squared_error: 1539.8119\n",
      "Epoch 245/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2505731.2500 - mae: 1067.8240 - mean_absolute_percentage_error: 14.3812 - root_mean_squared_error: 1582.1023\n",
      "Epoch 246/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2768883.5000 - mae: 1086.1431 - mean_absolute_percentage_error: 14.4014 - root_mean_squared_error: 1662.6769\n",
      "Epoch 247/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2530530.5000 - mae: 1064.8652 - mean_absolute_percentage_error: 14.0827 - root_mean_squared_error: 1590.1917\n",
      "Epoch 248/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2867104.7500 - mae: 1141.0829 - mean_absolute_percentage_error: 14.7713 - root_mean_squared_error: 1690.5933\n",
      "Epoch 249/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2625030.0000 - mae: 1059.7555 - mean_absolute_percentage_error: 13.8222 - root_mean_squared_error: 1618.1337\n",
      "Epoch 250/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2820936.5000 - mae: 1128.3755 - mean_absolute_percentage_error: 14.9507 - root_mean_squared_error: 1679.0326\n",
      "Epoch 251/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3018656.5000 - mae: 1174.5591 - mean_absolute_percentage_error: 15.1834 - root_mean_squared_error: 1734.8533\n",
      "Epoch 252/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2877933.7500 - mae: 1132.0667 - mean_absolute_percentage_error: 14.2839 - root_mean_squared_error: 1695.5664\n",
      "Epoch 253/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2663012.5000 - mae: 1107.9417 - mean_absolute_percentage_error: 14.7697 - root_mean_squared_error: 1629.8868\n",
      "Epoch 254/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3278353.5000 - mae: 1206.9022 - mean_absolute_percentage_error: 16.1643 - root_mean_squared_error: 1810.0516\n",
      "Epoch 255/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2855095.2500 - mae: 1155.3149 - mean_absolute_percentage_error: 15.0275 - root_mean_squared_error: 1689.3811\n",
      "Epoch 256/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4147281.0000 - mae: 1342.2369 - mean_absolute_percentage_error: 16.2747 - root_mean_squared_error: 2032.6039\n",
      "Epoch 257/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2848155.0000 - mae: 1144.1305 - mean_absolute_percentage_error: 14.5424 - root_mean_squared_error: 1683.9550\n",
      "Epoch 258/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2336391.2500 - mae: 1032.2755 - mean_absolute_percentage_error: 13.6238 - root_mean_squared_error: 1527.7961\n",
      "Epoch 259/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2477906.0000 - mae: 1043.2096 - mean_absolute_percentage_error: 13.6689 - root_mean_squared_error: 1572.6143\n",
      "Epoch 260/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2596532.5000 - mae: 1092.5148 - mean_absolute_percentage_error: 13.9597 - root_mean_squared_error: 1607.2086\n",
      "Epoch 261/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2998921.2500 - mae: 1166.0139 - mean_absolute_percentage_error: 14.1948 - root_mean_squared_error: 1727.3488\n",
      "Epoch 262/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2641220.7500 - mae: 1089.5536 - mean_absolute_percentage_error: 14.5186 - root_mean_squared_error: 1624.8494\n",
      "Epoch 263/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2776645.5000 - mae: 1096.1106 - mean_absolute_percentage_error: 14.6421 - root_mean_squared_error: 1663.7809\n",
      "Epoch 264/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3334508.7500 - mae: 1233.7628 - mean_absolute_percentage_error: 15.5416 - root_mean_squared_error: 1824.8427\n",
      "Epoch 265/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2770273.0000 - mae: 1122.9274 - mean_absolute_percentage_error: 15.0285 - root_mean_squared_error: 1663.2217\n",
      "Epoch 266/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3157910.7500 - mae: 1155.6306 - mean_absolute_percentage_error: 16.1522 - root_mean_squared_error: 1773.5430\n",
      "Epoch 267/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2782919.0000 - mae: 1115.2184 - mean_absolute_percentage_error: 14.6842 - root_mean_squared_error: 1667.9342\n",
      "Epoch 268/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2855396.5000 - mae: 1126.5374 - mean_absolute_percentage_error: 14.9990 - root_mean_squared_error: 1686.1586\n",
      "Epoch 269/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2947264.0000 - mae: 1122.1611 - mean_absolute_percentage_error: 15.0419 - root_mean_squared_error: 1716.4067\n",
      "Epoch 270/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2959821.2500 - mae: 1118.4019 - mean_absolute_percentage_error: 15.2137 - root_mean_squared_error: 1718.8889\n",
      "Epoch 271/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2659178.0000 - mae: 1114.8616 - mean_absolute_percentage_error: 14.2694 - root_mean_squared_error: 1630.3961\n",
      "Epoch 272/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2968009.0000 - mae: 1113.7336 - mean_absolute_percentage_error: 14.6008 - root_mean_squared_error: 1718.2301\n",
      "Epoch 273/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2676113.7500 - mae: 1086.8890 - mean_absolute_percentage_error: 13.6319 - root_mean_squared_error: 1632.1312\n",
      "Epoch 274/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2699203.5000 - mae: 1092.3102 - mean_absolute_percentage_error: 13.9964 - root_mean_squared_error: 1638.9990\n",
      "Epoch 275/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2487248.2500 - mae: 1059.6644 - mean_absolute_percentage_error: 13.7879 - root_mean_squared_error: 1574.8453\n",
      "Epoch 276/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2756717.7500 - mae: 1121.8394 - mean_absolute_percentage_error: 14.7434 - root_mean_squared_error: 1657.4236\n",
      "Epoch 277/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4060914.0000 - mae: 1336.3560 - mean_absolute_percentage_error: 16.9399 - root_mean_squared_error: 2010.4098\n",
      "Epoch 278/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2006374.2500 - mae: 972.6883 - mean_absolute_percentage_error: 13.6817 - root_mean_squared_error: 1415.6521\n",
      "Epoch 279/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1987329.2500 - mae: 948.7613 - mean_absolute_percentage_error: 12.9895 - root_mean_squared_error: 1408.8561\n",
      "Epoch 280/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1916308.7500 - mae: 944.2220 - mean_absolute_percentage_error: 13.0050 - root_mean_squared_error: 1383.6615\n",
      "Epoch 281/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2749827.0000 - mae: 1116.5023 - mean_absolute_percentage_error: 14.0135 - root_mean_squared_error: 1657.3987\n",
      "Epoch 282/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2816485.2500 - mae: 1108.2028 - mean_absolute_percentage_error: 14.6933 - root_mean_squared_error: 1676.6919\n",
      "Epoch 283/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3104316.0000 - mae: 1189.7435 - mean_absolute_percentage_error: 14.8955 - root_mean_squared_error: 1759.6488\n",
      "Epoch 284/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2532391.2500 - mae: 1074.6005 - mean_absolute_percentage_error: 14.3684 - root_mean_squared_error: 1590.7960\n",
      "Epoch 285/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2298442.0000 - mae: 1025.3989 - mean_absolute_percentage_error: 13.9578 - root_mean_squared_error: 1509.8136\n",
      "Epoch 286/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2671848.7500 - mae: 1094.9175 - mean_absolute_percentage_error: 14.3602 - root_mean_squared_error: 1632.7521\n",
      "Epoch 287/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2164306.0000 - mae: 984.9471 - mean_absolute_percentage_error: 13.1285 - root_mean_squared_error: 1470.4624\n",
      "Epoch 288/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2426633.7500 - mae: 1033.0884 - mean_absolute_percentage_error: 13.4101 - root_mean_squared_error: 1556.7831\n",
      "Epoch 289/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2798335.0000 - mae: 1131.3956 - mean_absolute_percentage_error: 15.3627 - root_mean_squared_error: 1672.0568\n",
      "Epoch 290/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2500618.5000 - mae: 1069.1592 - mean_absolute_percentage_error: 14.0099 - root_mean_squared_error: 1579.8545\n",
      "Epoch 291/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2922131.7500 - mae: 1161.1888 - mean_absolute_percentage_error: 15.1651 - root_mean_squared_error: 1708.4652\n",
      "Epoch 292/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2667544.2500 - mae: 1077.6584 - mean_absolute_percentage_error: 14.0897 - root_mean_squared_error: 1629.0720\n",
      "Epoch 293/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2284744.2500 - mae: 1017.2577 - mean_absolute_percentage_error: 13.9131 - root_mean_squared_error: 1510.1980\n",
      "Epoch 294/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2263872.5000 - mae: 1007.1862 - mean_absolute_percentage_error: 13.2602 - root_mean_squared_error: 1503.0194\n",
      "Epoch 295/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2858238.7500 - mae: 1145.9126 - mean_absolute_percentage_error: 14.3956 - root_mean_squared_error: 1689.0846\n",
      "Epoch 296/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2616959.7500 - mae: 1098.8196 - mean_absolute_percentage_error: 14.4274 - root_mean_squared_error: 1617.1328\n",
      "Epoch 297/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2996553.7500 - mae: 1156.3818 - mean_absolute_percentage_error: 15.8878 - root_mean_squared_error: 1729.0197\n",
      "Epoch 298/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2578828.2500 - mae: 1041.3462 - mean_absolute_percentage_error: 13.8179 - root_mean_squared_error: 1605.1154\n",
      "Epoch 299/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3226237.0000 - mae: 1199.2174 - mean_absolute_percentage_error: 15.0651 - root_mean_squared_error: 1794.5010\n",
      "Epoch 300/300\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2383745.2500 - mae: 1028.4951 - mean_absolute_percentage_error: 13.8789 - root_mean_squared_error: 1542.9772\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 13359336.0000 - mae: 1950.9587 - mean_absolute_percentage_error: 22.2333 - root_mean_squared_error: 3648.4075\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16225404.0000 - mae: 2075.8962 - mean_absolute_percentage_error: 22.2875 - root_mean_squared_error: 4022.6677\n",
      "train score:  [23275068.0, 3117.943603515625, 4824.42431640625, 36.64447784423828]\n",
      "eval score:  [14652408.0, 2245.87109375, 3827.846435546875, 26.297163009643555]\n",
      "test score:  [14370739.0, 1989.0135498046875, 3790.875732421875, 22.34033203125]\n"
     ]
    }
   ],
   "source": [
    "#hidden_layers, neurons, optimizer, learning_rate, regularization    \n",
    "#def create_model(hidden_layers, neurons, optimizer, learning_rate, regularization):\n",
    "model = create_model(**best_params)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=300, batch_size=64)\n",
    "score1= model.evaluate(X_train_scaled, y_train)\n",
    "score2 = model.evaluate(X_eval_scaled, y_eval)\n",
    "# Evaluate the model\n",
    "score3 = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "print(\"train score: \", score1)\n",
    "print(\"eval score: \", score2)\n",
    "print(\"test score: \", score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kobra\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Sequential.add() got an unexpected keyword argument 'kernel_regularizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#hidden_layers, neurons, optimizer, learning_rate, regularization    \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m110\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madamW\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Train the model and also display the error on the evaluation set\u001b[39;00m\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(hidden_layers, neurons, optimizer, learning_rate, regularization)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(hidden_layers, neurons, optimizer, learning_rate, regularization):\n\u001b[0;32m     12\u001b[0m     model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneurons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregularizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregularization\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLeakyReLU(neurons), kernel_regularizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mregularizers\u001b[38;5;241m.\u001b[39ml2(regularization))\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(hidden_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: Sequential.add() got an unexpected keyword argument 'kernel_regularizer'"
     ]
    }
   ],
   "source": [
    "#hidden_layers, neurons, optimizer, learning_rate, regularization    \n",
    "model = create_model(35, 110, 'adamW', 0.001, 0.3)\n",
    "\n",
    "\n",
    "# Train the model and also display the error on the evaluation set\n",
    "model.fit(X_train_scaled, y_train, epochs=150, batch_size=64)\n",
    "score1 = model.evaluate(X_train_scaled, y_train)\n",
    "score2 = model.evaluate(X_eval_scaled, y_eval)\n",
    "# Evaluate the model\n",
    "score3 = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "print(\"train score: \", score1)\n",
    "print(\"eval score: \", score2)\n",
    "print(\"test score: \", score3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "perl"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_ANN.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#load model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_ANN.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('model_ANN_2.h5')\n",
    "\n",
    "#load model\n",
    "model = tf.keras.models.load_model('model_ANN_2\".h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
