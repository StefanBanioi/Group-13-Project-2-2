{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pLjRQ5d-jiJH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EzQV8jEbjiJI"
      },
      "outputs": [],
      "source": [
        "# Path to the CSV file\n",
        "csv_file_path = 'Data\\healthinsurance2.csv'  # Replace with the actual path to your CSV file\n",
        "# Read the CSV file\n",
        "\n",
        "mydata = pd.read_csv(csv_file_path)\n",
        "\n",
        "mydata = mydata.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "27IO25dEjiJJ",
        "outputId": "197d97de-f33c-4a2b-a8b2-81a7bbd30eed"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "mydata['city'] = le.fit_transform(mydata['city'])\n",
        "X = mydata.drop(columns=['claim', 'city'])\n",
        "y = mydata['claim']\n",
        "\n",
        "\n",
        "# X = data.drop('PremiumPrice', axis=1)\n",
        "# y = data['PremiumPrice']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=69)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "#This was used for Hyperparameter tuning using RandomizedSearchCV(long process and commented out since we saved the parameters)\n",
        "\n",
        "# possibleParameters= {\n",
        "#   'max_depth' : range (2, 51, 1),\n",
        "#   'n_estimators'  : range (50,1000,25),\n",
        "#   'learning_rate' : [0.01, 0.02,0.03,0.05,0.1,0.2],\n",
        "#   'subsample':  [0.65,0.7,0.75,0.8,0.85,0.95,1],\n",
        "#   'colsample_bytree':[0.80,0.85,0.90,0.95,1],\n",
        "# }\n",
        "\n",
        "\n",
        "# rand_search = RandomizedSearchCV(\n",
        "#     xgb.XGBRegressor(random_state=69),\n",
        "#     param_distributions=possibleParameters,\n",
        "#     n_iter=300,  # Set the number of iterations to 1\n",
        "#     cv=5, n_jobs=-1\n",
        "# )\n",
        "# rand_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# best_params = rand_search.best_params_\n",
        "\n",
        "# print(\"Best Parameters:\", best_params)\n",
        "\n",
        "\n",
        "# #best parameters\n",
        "\n",
        "\n",
        "# #predictions using the best model\n",
        "# model = rand_search.best_estimator_\n",
        "# Fit the model to the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cxA-PIGXjiJJ"
      },
      "outputs": [],
      "source": [
        "# # Create an instance of XGBRegressor with the given parameters\n",
        "model = xgb.XGBRegressor(\n",
        "        tree_method='hist',  # Comment out if no GPU is available\n",
        "        max_depth=32,\n",
        "        learning_rate=0.03,\n",
        "        n_estimators=475,\n",
        "        subsample=0.65,\n",
        "        colsample_bytree=0.85,\n",
        "        random_state = 69)\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "#save model\n",
        "model.save_model('xgboost_model.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PoPOvgiZekTl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[11253.414   7152.725  28468.803  ...  1146.8208  7323.7075 18223.47  ]\n",
            "[10942.113   1629.8196 14283.489  ...  4934.718   8824.013  12129.613 ]\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test_scaled)\n",
        "print(y_pred)\n",
        "y_pred_train = model.predict(X_train_scaled)\n",
        "print(y_pred_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "O6BjCdughG2V"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train data\n",
            "Mae:  1.8930161876015217\n",
            "RMSE:  16.750692274521352\n",
            "MAPE:  0.0001560959885768162\n",
            "test data\n",
            "Mae:  327.74715078159346\n",
            "RMSE:  1957.356673751635\n",
            "MAPE:  0.02490968381422672\n"
          ]
        }
      ],
      "source": [
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mape= mean_absolute_percentage_error(y_test,y_pred)\n",
        "\n",
        "mae_train= mean_absolute_error(y_train, y_pred_train)\n",
        "mse_train= mean_squared_error(y_train,y_pred_train)\n",
        "mape_train= mean_absolute_percentage_error(y_train,y_pred_train)\n",
        "print('train data')\n",
        "print(\"Mae: \", mae_train)\n",
        "print(\"RMSE: \",math.sqrt(mse_train))\n",
        "print(\"MAPE: \",mape_train)\n",
        "print('test data')\n",
        "\n",
        "print(\"Mae: \", mae)\n",
        "print(\"RMSE: \", math.sqrt(mse))\n",
        "print(\"MAPE: \", mape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAPE:  0.02490968381422672\n"
          ]
        }
      ],
      "source": [
        "loaded_model = xgb.XGBRegressor()\n",
        "loaded_model.load_model('xgboost_model.json')\n",
        "y_pred = loaded_model.predict(X_test_scaled)\n",
        "mape= mean_absolute_percentage_error(y_test,y_pred)\n",
        "print(\"MAPE: \",mape)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
